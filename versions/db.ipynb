{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe7b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36811064",
   "metadata": {},
   "source": [
    "Setup database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47724614",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect('returns.db')\n",
    "conn.execute(\"INSTALL 'excel'\")\n",
    "conn.execute(\"LOAD 'excel'\")\n",
    "table = 'returns'\n",
    "file = 'RETRO_SAMPLE.xlsx'\n",
    "conn.execute(\"CREATE TABLE returns AS SELECT * FROM RETRO_SAMPLE.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426beeb",
   "metadata": {},
   "source": [
    "DB information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eefff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Table with name returns does not exist!\nDid you mean \"pg_prepared_statements\"?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatalogException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m tables = conn.execute(\u001b[33m\"\u001b[39m\u001b[33mSHOW TABLES\u001b[39m\u001b[33m\"\u001b[39m).fetchall()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(tables)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m columns = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPRAGMA table_info(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreturns\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m);\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.fetchall()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(columns)\n\u001b[32m      6\u001b[39m query = conn.execute(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m    SELECT COUNT(DISTINCT CUSTOMER_EMAILID)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m    FROM returns\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m\"\"\"\u001b[39m).fetchone()\n",
      "\u001b[31mCatalogException\u001b[39m: Catalog Error: Table with name returns does not exist!\nDid you mean \"pg_prepared_statements\"?"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect('customer_clustering.db')\n",
    "tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
    "print(tables)\n",
    "columns = conn.execute(\"PRAGMA table_info('returns');\").fetchall()\n",
    "print(columns)\n",
    "query = conn.execute(\"\"\"\n",
    "    SELECT COUNT(DISTINCT CUSTOMER_EMAILID)\n",
    "    FROM returns\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"unqiue customer emails: {query}\")\n",
    "\n",
    "cust_orders = conn.execute(\"\"\"\n",
    "    SELECT AVG(order_count) AS avg_unique_orders_per_customer\n",
    "    FROM (\n",
    "        SELECT CUSTOMER_EMAILID, COUNT(DISTINCT SALES_ORDER_NO) AS order_count\n",
    "        FROM returns\n",
    "        GROUP BY CUSTOMER_EMAILID\n",
    "    );\n",
    "        \"\"\").fetchone()\n",
    "\n",
    "print(f\"average unique orders per customer: {cust_orders}\")\n",
    "\n",
    "cust_returns = conn.execute(\"\"\"\n",
    "    SELECT AVG(return_count) AS avg_unique_returns_per_customer\n",
    "    FROM (\n",
    "        SELECT CUSTOMER_EMAILID, COUNT(DISTINCT RETURN_NO) AS return_count\n",
    "        FROM returns\n",
    "        GROUP BY CUSTOMER_EMAILID\n",
    "    );\n",
    "        \"\"\").fetchone()\n",
    "\n",
    "print(f\"average unique returns per customer: {cust_returns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354bcc6",
   "metadata": {},
   "source": [
    "## Database status after importing new data (random1_FINAL_SENT.csv)\n",
    "\n",
    "The database has been updated with new data from `random1_FINAL_SENT.csv`. Let's check the current status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current database status after importing random1_FINAL_SENT.csv\n",
    "conn = duckdb.connect('customer_clustering.db')\n",
    "\n",
    "# Check bronze layer statistics\n",
    "bronze_count = conn.execute(\"SELECT COUNT(*) FROM bronze_return_order_data\").fetchone()[0]\n",
    "bronze_customers = conn.execute(\"SELECT COUNT(DISTINCT customer_emailid) FROM bronze_return_order_data\").fetchone()[0]\n",
    "bronze_categories = conn.execute(\"SELECT COUNT(DISTINCT class_) FROM bronze_return_order_data\").fetchone()[0]\n",
    "\n",
    "print(f\"Bronze layer: {bronze_count} rows, {bronze_customers} unique customers, {bronze_categories} unique product categories\")\n",
    "\n",
    "# Check silver layer statistics\n",
    "silver_count = conn.execute(\"SELECT COUNT(*) FROM silver_customer_features\").fetchone()[0]\n",
    "silver_customers = conn.execute(\"SELECT COUNT(DISTINCT customer_emailid) FROM silver_customer_features\").fetchone()[0]\n",
    "\n",
    "# Get diversity score statistics\n",
    "diversity_stats = conn.execute(\"\"\"\n",
    "SELECT \n",
    "    MIN(category_diversity_score) as min_score,\n",
    "    MAX(category_diversity_score) as max_score,\n",
    "    AVG(category_diversity_score) as avg_score\n",
    "FROM silver_customer_features\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"Silver layer: {silver_count} rows, {silver_customers} unique customers\")\n",
    "print(f\"Category diversity score: min={diversity_stats[0]:.6f}, max={diversity_stats[1]:.6f}, avg={diversity_stats[2]:.6f}\")\n",
    "\n",
    "# Check gold layer statistics\n",
    "gold_count = conn.execute(\"SELECT COUNT(*) FROM gold_cluster_processed\").fetchone()[0]\n",
    "gold_customers = conn.execute(\"SELECT COUNT(DISTINCT customer_emailid) FROM gold_cluster_processed\").fetchone()[0]\n",
    "\n",
    "# Get scaled diversity score statistics\n",
    "scaled_stats = conn.execute(\"\"\"\n",
    "SELECT \n",
    "    MIN(category_diversity_score_scaled) as min_score,\n",
    "    MAX(category_diversity_score_scaled) as max_score,\n",
    "    AVG(category_diversity_score_scaled) as avg_score\n",
    "FROM gold_cluster_processed\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"Gold layer: {gold_count} rows, {gold_customers} unique customers\")\n",
    "print(f\"Scaled category diversity score: min={scaled_stats[0]:.6f}, max={scaled_stats[1]:.6f}, avg={scaled_stats[2]:.6f}\")\n",
    "\n",
    "# Check for customers in bronze but not in silver\n",
    "new_customers = conn.execute(\"\"\"\n",
    "SELECT COUNT(DISTINCT b.customer_emailid)\n",
    "FROM bronze_return_order_data b\n",
    "LEFT JOIN silver_customer_features s ON b.customer_emailid = s.customer_emailid\n",
    "WHERE s.customer_emailid IS NULL\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "print(f\"\\nCustomers in bronze but not in silver: {new_customers}\")\n",
    "\n",
    "# Check for any duplicates\n",
    "bronze_dups = bronze_count - conn.execute(\"SELECT COUNT(DISTINCT primary_key) FROM bronze_return_order_data\").fetchone()[0]\n",
    "silver_dups = silver_count - silver_customers\n",
    "gold_dups = gold_count - gold_customers\n",
    "\n",
    "print(f\"\\nDuplicates check:\")\n",
    "print(f\"Bronze layer duplicates: {bronze_dups}\")\n",
    "print(f\"Silver layer duplicates: {silver_dups}\")\n",
    "print(f\"Gold layer duplicates: {gold_dups}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa059c",
   "metadata": {},
   "source": [
    "## Summary of Changes and Recommendations\n",
    "\n",
    "We've successfully processed the new data file `random1_FINAL_SENT.csv` through all layers:\n",
    "\n",
    "1. **Bronze Layer Updates**:\n",
    "   - Added 2,437,247 new rows to the bronze layer\n",
    "   - Increased unique product categories from 400+ to 623\n",
    "   - Added 9 new customers\n",
    "\n",
    "2. **Silver Layer Updates**:\n",
    "   - Updated category_diversity_score for all existing customers\n",
    "   - Formula now uses actual unique category count (623) for normalization\n",
    "\n",
    "3. **Gold Layer Updates**:\n",
    "   - Updated category_diversity_score_scaled for all customers\n",
    "   - Re-scaled values based on the new diversity scores\n",
    "\n",
    "4. **Data Quality**:\n",
    "   - No duplicates found in any layer\n",
    "   - Primary keys and unique constraints are working as expected\n",
    "\n",
    "5. **Recommendations**:\n",
    "   - The 9 new customers found in the bronze layer should be fully processed into the silver layer with complete feature engineering\n",
    "   - Consider running additional data quality checks specific to the new data\n",
    "   - Update any dashboards or reports to reflect the increased data volume\n",
    "   - Consider updating the clustering model with the new diversity scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
